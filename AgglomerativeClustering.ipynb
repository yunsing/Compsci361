{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AgglomerativeClustering.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yunsing/Compsci361/blob/master/AgglomerativeClustering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30lNfB3DybVB",
        "colab_type": "text"
      },
      "source": [
        "# Hierarchical clustering\n",
        "\n",
        "Hierarchical clustering, also known as hierarchical cluster analysis, is an algorithm that groups similar objects into groups called clusters. The endpoint is a set of clusters, where each cluster is distinct from each other cluster, and the objects within each cluster are broadly similar to each other."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhaogH-UzFdA",
        "colab_type": "text"
      },
      "source": [
        "# Case 1\n",
        "\n",
        "We use ` sklearn`, we initalise data with random seeds."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L18F9z-fCuia",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import statements\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.metrics import adjusted_rand_score\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# create blobs\n",
        "data = make_blobs(n_samples=200, n_features=2, centers=4, cluster_std=1.6, random_state=50)\n",
        "\n",
        "# create np array for data points\n",
        "points = data[0]\n",
        "\n",
        "# create scatter plot\n",
        "plt.scatter(data[0][:,0], data[0][:,1], c=data[1], cmap='viridis')\n",
        "plt.xlim(-15,15)\n",
        "plt.ylim(-15,15)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgMVH_5-zV27",
        "colab_type": "text"
      },
      "source": [
        "We used ` AgglomerativeClustering` from `sklearn`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYQTkpRP6Izy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import hierarchical clustering libraries\n",
        "import scipy.cluster.hierarchy as sch\n",
        "from sklearn.cluster import AgglomerativeClustering"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dh8e6fhW2jT0",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Dendrograms are hierarchical plots of clusters where the length of the bars represent the distance to the next cluster centre.\n",
        "\n",
        "\n",
        "**Question**: Based on the dendogram how many clusters do you think exist in this dataset?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z21tIH4HCCrc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create dendrogram\n",
        "dendrogram = sch.dendrogram(sch.linkage(points, method='ward'))\n",
        "\n",
        "# create clusters\n",
        "hc = AgglomerativeClustering(n_clusters=3, affinity = 'euclidean', linkage = 'ward')\n",
        "\n",
        "\n",
        "y_hc = hc.fit_predict(points)\n",
        "print(y_hc) ## print clusters 0,1,2\n",
        "\n",
        "plt.title('Hierarchical Clustering Dendrogram (Ward)')\n",
        "plt.xlabel('sample index')\n",
        "plt.ylabel('distance')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gSPnCpw2aOf",
        "colab_type": "text"
      },
      "source": [
        "**Whiskey dataset**\n",
        "\n",
        "Let’s load it in."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPE-or6sHAwH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "whiskey = pd.read_csv('https://s3.eu-west-2.amazonaws.com/free.trainingdatascience.com/data/whiskies.csv')\n",
        "cols = ['Body', 'Sweetness', 'Smoky', 'Medicinal', 'Tobacco',\n",
        "       'Honey', 'Spicy', 'Winey', 'Nutty', 'Malty', 'Fruity', 'Floral']\n",
        "X = whiskey[cols]\n",
        "y = whiskey['Distillery']\n",
        "display(X.head())\n",
        "display(y.head())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBAde-AS26jv",
        "colab_type": "text"
      },
      "source": [
        "Plot a dendrogram of the whiskey data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mY9BQ3FIoWv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.cluster.hierarchy import dendrogram, linkage\n",
        "\n",
        "\n",
        "linkage_matrix = linkage(X, 'ward')\n",
        "\n",
        "figure = plt.figure(figsize=(7.5, 5))\n",
        "\n",
        "\n",
        "\n",
        "dendrogram(\n",
        "    linkage_matrix,\n",
        "    color_threshold=0,\n",
        ")\n",
        "\n",
        "# create clusters\n",
        "hc = AgglomerativeClustering(n_clusters=2, affinity = 'euclidean', linkage = 'ward')\n",
        "\n",
        "# save clusters for chart\n",
        "y_hc = hc.fit_predict(X)\n",
        "\n",
        "plt.title('Hierarchical Clustering Dendrogram (Ward)')\n",
        "plt.xlabel('sample index')\n",
        "plt.ylabel('distance')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYb7eZsL0ez_",
        "colab_type": "text"
      },
      "source": [
        "Try playing with the different parameters in the dendrogram. Look up the aggomerative documentation.\n",
        "        p\n",
        "        truncate_mode\n",
        "\n",
        "Plot a dendrogram of the whiskey data with p = 24.\n",
        "\n",
        "**Question:** How many clusters are there in this dataset?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLvKS-jM2HUE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.cluster.hierarchy import dendrogram, linkage\n",
        "\n",
        "linkage_matrix = linkage(X, 'ward')\n",
        "figure = plt.figure(figsize=(7.5, 5))\n",
        "dendrogram(\n",
        "    linkage_matrix,\n",
        "    truncate_mode='lastp',  # show only the last p merged clusters\n",
        "    p=24,  # show only the last p merged clusters\n",
        "    leaf_rotation=90.,\n",
        "    leaf_font_size=12.,\n",
        "    show_contracted=True,  # to get a distribution impression in truncated branches\n",
        ")\n",
        "plt.title('Hierarchical Clustering Dendrogram (Ward)')\n",
        "plt.xlabel('sample index')\n",
        "plt.ylabel('distance')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKVKx6VV5xzW",
        "colab_type": "text"
      },
      "source": [
        "One way to evaluate the quality of clustering is using a score, such as Silhouette Score. \n",
        "\n",
        "**Question**: Can you use this to evaluate the number of clusters in the dataset?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezvZWsU_5wf6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "silhouette_score(X,hc.labels_,metric='euclidean')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-GhpKEt4ECL",
        "colab_type": "text"
      },
      "source": [
        "**Task** \n",
        "\n",
        "Try different linkage settings inkage : `{“ward”, “complete”, “average”, “single”}`. \n",
        "\n",
        "Try different affinity settings string or callable, default: “euclidean” such as:\n",
        "`` “euclidean”, “l1”, “l2”, “manhattan”, “cosine”. If linkage is “ward”, only “euclidean” is accepted`.\n",
        "\n",
        "**Question**: What did you observe?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1z0rGd07LTMW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.cluster.hierarchy import dendrogram, linkage\n",
        "\n",
        "linkage_matrix = linkage(X, 'complete')\n",
        "figure = plt.figure(figsize=(7.5, 5))\n",
        "dendrogram(\n",
        "    linkage_matrix,\n",
        "    color_threshold=0,\n",
        ")\n",
        "plt.title('Hierarchical Clustering Dendrogram (Single)')\n",
        "plt.xlabel('sample index')\n",
        "plt.ylabel('distance')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}