{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kmeans.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yunsing/Compsci361/blob/master/kmeans.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rg9NPr-uA5UD",
        "colab_type": "text"
      },
      "source": [
        "# k-means clustering\n",
        "There are many clustering algorithms are available in Scikit-Learn and the simplest clustering algorthm to understand is  known as k-means clustering, which is implemented in `sklearn.cluster.KMeans`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njB9KtkNAz1D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns; sns.set()  \n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOUgAZMIDzSb",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "**Introducing k-Means**\n",
        "\n",
        "The k-means algorithm searches for a pre-determined number of clusters within an unlabeled multidimensional dataset. \n",
        "\n",
        "First, we generate a two-dimensional dataset containing four distinct blobs. To emphasize that this is an unsupervised algorithm, we will leave the labels out of the visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTA9BIwxEIP4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets.samples_generator import make_blobs\n",
        "X, y_true = make_blobs(n_samples=300, centers=4, cluster_std=0.60, random_state=1)\n",
        "plt.scatter(X[:, 0], X[:, 1], s=50);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePbbaT0KE5EU",
        "colab_type": "text"
      },
      "source": [
        "It is relatively easy to pick out the four clusters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZN-89iGKE6t1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "kmeans = KMeans(n_clusters=4)\n",
        "kmeans.fit(X)\n",
        "y_kmeans = kmeans.predict(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asvmZ6XwFBLn",
        "colab_type": "text"
      },
      "source": [
        "Now visualize the results by plotting the data colored by these labels. We will also plot the cluster centers as determined by the k-means estimator:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLd3c6nyEPlr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.scatter(X[:, 0], X[:, 1], c=y_kmeans, s=50, cmap='viridis')\n",
        "\n",
        "centers = kmeans.cluster_centers_\n",
        "plt.scatter(centers[:, 0], centers[:, 1], c='black', s=200, alpha=0.5);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ya_vmQ6TFQRR",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "The good news is that the k-means algorithm (at least in this simple case) assigns the points to clusters very similarly to how we might assign them by eye. But you might wonder how this algorithm finds these clusters so quickly!\n",
        "\n",
        "\n",
        "### **Setting the right k**\n",
        " \n",
        "The number of clusters must be selected beforehand\n",
        "\n",
        "Another common challenge with k-means is that you must tell it how many clusters you expect: it cannot learn the number of clusters from the data. \n",
        "\n",
        "If we ask the algorithm to identify ten clusters (k=10), k-means will proceed and find the best ten clusters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lxhrqi0FhOM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = KMeans(10, random_state=1).fit_predict(X)\n",
        "plt.scatter(X[:, 0], X[:, 1], c=labels,\n",
        "            s=50, cmap='viridis');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRGqO1K4G7Zt",
        "colab_type": "text"
      },
      "source": [
        "### k-means is limited to linear cluster boundaries\n",
        "\n",
        "The fundamental model assumptions of k-means (points will be closer to their own cluster center than to others) means that the algorithm will often be ineffective if the clusters have complicated geometries.\n",
        "\n",
        "Consider the following data, along with the cluster labels found by the typical k-means approach:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Epe49KAuIYcA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import make_moons\n",
        "X, y = make_moons(200, noise=.05, random_state=1)\n",
        "                  \n",
        "labels = KMeans(2, random_state=0).fit_predict(X)\n",
        "plt.scatter(X[:, 0], X[:, 1], c=labels,\n",
        "            s=50, cmap='viridis');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JDjQDY4Imr_",
        "colab_type": "text"
      },
      "source": [
        "Why does it separate the clusters as shown above?\n",
        "\n",
        "\n",
        "What happens if data is randomly distributed?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAODP-QnKZd_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets.samples_generator import make_blobs\n",
        "X, y_true = make_blobs(n_samples=300, centers=100, cluster_std=20.0, random_state=1)\n",
        "plt.scatter(X[:, 0], X[:, 1], s=50);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z10FktvIQue_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = KMeans(10, random_state=1).fit_predict(X)\n",
        "plt.scatter(X[:, 0], X[:, 1], c=labels,\n",
        "            s=50, cmap='viridis');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2D4YbdkiI-uJ",
        "colab_type": "text"
      },
      "source": [
        "What can you deduce from this?"
      ]
    }
  ]
}