{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DBScan.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yunsing/Compsci361/blob/master/DBScan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eknGQF7wl5k",
        "colab_type": "text"
      },
      "source": [
        "# DBSCAN\n",
        "\n",
        "Density-based spatial clustering of applications with noise (DBSCAN) is a well-known data clustering algorithm. DBSCAN groups together points that are close to each other based on a distance measurement (usually Euclidean distance) and a minimum number of points. It also marks as outliers the points that are in low-density regions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swNbpWIvwIgp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn import metrics\n",
        "from sklearn.datasets.samples_generator import make_blobs\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCQiVckVwm8D",
        "colab_type": "text"
      },
      "source": [
        "Generate sample data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QINr9Iw_wlRk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "centers = [[1, 1], [-1, -1], [1, -1]]\n",
        "X, labels_true = make_blobs(n_samples=750, centers=centers, cluster_std=0.4,\n",
        "                            random_state=0)\n",
        "\n",
        "X = StandardScaler().fit_transform(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDRLfbB8wrdx",
        "colab_type": "text"
      },
      "source": [
        "Compute DBSCAN.\n",
        "\n",
        "The DBSCAN algorithm basically requires 2 parameters:\n",
        "\n",
        "    eps: the minimum distance between two points. It means that if the distance between two points is lower or equal to this value (eps), these points are considered neighbors.\n",
        "\n",
        "    minPoints: the minimum number of points to form a dense region. For example, if we set the minPoints parameter as 5, then we need at least 5 points to form a dense region."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWJa1fWkwrx0",
        "colab_type": "code",
        "outputId": "73cd97ac-61cc-4dcb-c398-6f892b514461",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "db = DBSCAN(eps=0.3, min_samples=10).fit(X)\n",
        "core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
        "core_samples_mask[db.core_sample_indices_] = True\n",
        "labels = db.labels_\n",
        "\n",
        "# Number of clusters in labels, ignoring noise if present.\n",
        "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
        "\n",
        "print('Estimated number of clusters: %d' % n_clusters_)\n",
        "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels_true, labels))\n",
        "print(\"Completeness: %0.3f\" % metrics.completeness_score(labels_true, labels))\n",
        "print(\"V-measure: %0.3f\" % metrics.v_measure_score(labels_true, labels))\n",
        "print(\"Adjusted Rand Index: %0.3f\"\n",
        "      % metrics.adjusted_rand_score(labels_true, labels))\n",
        "print(\"Adjusted Mutual Information: %0.3f\"\n",
        "      % metrics.adjusted_mutual_info_score(labels_true, labels))\n",
        "print(\"Silhouette Coefficient: %0.3f\"\n",
        "      % metrics.silhouette_score(X, labels))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Estimated number of clusters: 3\n",
            "Homogeneity: 0.953\n",
            "Completeness: 0.883\n",
            "V-measure: 0.917\n",
            "Adjusted Rand Index: 0.952\n",
            "Adjusted Mutual Information: 0.883\n",
            "Silhouette Coefficient: 0.626\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:732: FutureWarning: The behavior of AMI will change in version 0.22. To match the behavior of 'v_measure_score', AMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1gBmVxUwxqD",
        "colab_type": "text"
      },
      "source": [
        "Number of clusters in labels, ignoring noise if present."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsusHZSuwx7B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Black removed and is used for noise instead.\n",
        "unique_labels = set(labels)\n",
        "colors = [plt.cm.Spectral(each)\n",
        "          for each in np.linspace(0, 1, len(unique_labels))]\n",
        "for k, col in zip(unique_labels, colors):\n",
        "    if k == -1:\n",
        "        # Black used for noise.\n",
        "        col = [0, 0, 0, 1]\n",
        "\n",
        "    class_member_mask = (labels == k)\n",
        "\n",
        "    xy = X[class_member_mask & core_samples_mask]\n",
        "    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
        "             markeredgecolor='k', markersize=14)\n",
        "\n",
        "    xy = X[class_member_mask & ~core_samples_mask]\n",
        "    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
        "             markeredgecolor='k', markersize=6)\n",
        "\n",
        "plt.title('Estimated number of clusters: %d' % n_clusters_)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUrdtCWvxY4y",
        "colab_type": "text"
      },
      "source": [
        "# Example: Using Iris"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6A6gOTTNxZRT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing Modules\n",
        "from sklearn.datasets import load_iris\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.decomposition import PCA"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFsJtNjOxhd7",
        "colab_type": "text"
      },
      "source": [
        "Load the iris data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9R3fZaGvxfNy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load Dataset\n",
        "iris = load_iris()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2W3JgEixpGY",
        "colab_type": "text"
      },
      "source": [
        "Using PCA to reduce correlation. Use DBScan 2 cluster."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AryUo5AdxpeH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dbscan = DBSCAN()\n",
        "\n",
        "# Fitting\n",
        "dbscan.fit(iris.data)\n",
        "\n",
        "# Transoring Using PCA\n",
        "pca = PCA(n_components=2).fit(iris.data)\n",
        "pca_2d = pca.transform(iris.data)\n",
        "\n",
        "# Plot based on Class\n",
        "for i in range(0, pca_2d.shape[0]):\n",
        "    if dbscan.labels_[i] == 0:\n",
        "        c1 = plt.scatter(pca_2d[i, 0], pca_2d[i, 1], c='r', marker='+')\n",
        "    elif dbscan.labels_[i] == 1:\n",
        "        c2 = plt.scatter(pca_2d[i, 0], pca_2d[i, 1], c='g', marker='o')\n",
        "    elif dbscan.labels_[i] == -1:\n",
        "        c3 = plt.scatter(pca_2d[i, 0], pca_2d[i, 1], c='b', marker='*')\n",
        "\n",
        "plt.legend([c1, c2, c3], ['Cluster 1', 'Cluster 2', 'Noise'])\n",
        "plt.title('DBSCAN finds 2 clusters and Noise')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}